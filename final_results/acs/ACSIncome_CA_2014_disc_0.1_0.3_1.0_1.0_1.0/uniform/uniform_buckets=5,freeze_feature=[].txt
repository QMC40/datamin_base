-------------------------------------CONFIG-------------------------------------
neptune_config:
 neptune_run_label: None
 use_neptune: False
dataset_config:
 dataset: ACSIncome
 acs_state: CA
 acs_year: 2014
 shift_state: None
 shift_year: None
 freeze_feature: []
 add_syn: False
 bucketization_percent: 1.0
 train_percent: 1.0
 adv_percent: 1.0
 sens_feats: disc
 val_split: 0.1
 test_split: 0.3
 batch_size: 256
eval_config:
Classifiers:
 Classifier 0:
  Model: mlp2 Epochs: 20 LR: 0.01 WD: 0.0
Adversary 0:
  Model: mlp2 Epochs: 20 LR: 0.01 WD: 0.0
Adversary 1:
  Model: mlp2 Epochs: 20 LR: 0.01 WD: 0.0
min_config:
uniform_buckets=5,freeze_feature=[]
seed: 123
device: cpu
out_dir: final_results/acs
compute_guarantees: False
get_clf_upper_bound: False
fairness_sens_col: None
num_workers: 12
logger_level: INFO
-----------------------------------CONFIG END-----------------------------------

majority class acc (clf ACC LB): train_acc=0.643 test_acc=0.651
feat=COW, majority_freqs: train=0.653 test=0.652
feat=MAR, majority_freqs: train=0.534 test=0.536
feat=OCCP, majority_freqs: train=0.032 test=0.030
feat=POBP, majority_freqs: train=0.462 test=0.458
feat=RELP, majority_freqs: train=0.479 test=0.476
feat=SEX, majority_freqs: train=0.534 test=0.535
feat=RAC1P, majority_freqs: train=0.633 test=0.636
[adv] naive majority freq guess (adv ACC LB): train_acc=0.475, test_acc=0.474

Running data minimizer: uniform
Final bucketizations:
================
Bucketization:
AGEP (cont): tot_buckets=5, borders=[0.2, 0.4, 0.6, 0.8]
		Train set values would map to 5 buckets: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4]
SCHL (cont): tot_buckets=5, borders=[0.2, 0.4, 0.6, 0.8]
		Train set values would map to 5 buckets: [0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4]
WKHP (cont): tot_buckets=5, borders=[0.2, 0.4, 0.6, 0.8]
		Train set values would map to 5 buckets: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4]
COW (disc): tot_buckets=5, mapping=[3, 1, 0, 0, 3, 3, 2, 0]
MAR (disc): tot_buckets=5, mapping=[0, 1, 1, 0, 0]
OCCP (disc): tot_buckets=5, mapping=[3, 0, 4, 1, 2, 3, 3, 3, 0, 2, 4, 3, 0, 4, 4, 4, 2, 0, 1, 1, 3, 1, 2, 2, 1, 2, 0, 2, 4, 1, 3, 1, 3, 2, 4, 2, 1, 4, 2, 4, 0, 2, 4, 2, 4, 0, 1, 1, 4, 4, 3, 4, 2, 4, 4, 1, 0, 1, 2, 1, 1, 3, 2, 2, 4, 3, 3, 0, 2, 1, 3, 2, 3, 4, 3, 4, 0, 3, 4, 1, 3, 4, 1, 2, 1, 0, 3, 4, 0, 1, 2, 2, 0, 4, 2, 3, 1, 3, 3, 1, 2, 4, 1, 3, 4, 2, 2, 2, 3, 3, 4, 1, 3, 1, 1, 4, 0, 4, 1, 4, 0, 3, 3, 1, 4, 2, 1, 2, 4, 2, 3, 4, 4, 2, 4, 3, 2, 1, 1, 1, 4, 0, 3, 2, 1, 3, 0, 2, 3, 4, 4, 4, 2, 1, 2, 3, 0, 2, 1, 4, 2, 0, 3, 3, 3, 0, 1, 3, 1, 4, 4, 2, 4, 2, 4, 2, 3, 3, 0, 1, 4, 0, 0, 4, 1, 4, 4, 2, 0, 0, 1, 4, 0, 3, 3, 4, 3, 0, 0, 1, 3, 0, 4, 2, 2, 4, 3, 0, 2, 2, 1, 1, 0, 2, 2, 3, 0, 2, 2, 2, 3, 1, 4, 0, 0, 1, 0, 4, 3, 1, 0, 0, 4, 4, 4, 1, 0, 3, 4, 4, 4, 0, 0, 2, 3, 2, 4, 2, 3, 4, 0, 0, 4, 0, 2, 0, 4, 0, 2, 4, 0, 1, 0, 0, 4, 1, 1, 1, 0, 3, 4, 1, 1, 0, 4, 0, 4, 4, 1, 3, 4, 1, 2, 3, 0, 2, 0, 1, 1, 1, 1, 3, 2, 0, 0, 4, 1, 2, 0, 4, 3, 4, 2, 0, 4, 4, 4, 2, 4, 4, 1, 4, 3, 0, 4, 0, 0, 1, 2, 2, 2, 0, 4, 1, 4, 1, 1, 2, 4, 3, 3, 2, 3, 0, 2, 0, 3, 4, 4, 1, 2, 4, 0, 1, 4, 3, 4, 0, 4, 4, 3, 2, 0, 4, 4, 3, 3, 4, 4, 4, 2, 1, 3, 0, 0, 3, 1, 4, 2, 0, 0, 0, 0, 2, 3, 1, 4, 4, 2, 3, 2, 4, 1, 4, 0, 4, 2, 4, 3, 0, 3, 1, 1, 1, 4, 4, 4, 2, 4, 2, 2, 4, 1, 2, 4, 2, 3, 0, 0, 0, 3, 3, 1, 2, 3, 1, 0, 0, 2, 4, 3, 2, 3, 3, 1, 4, 0, 4, 3, 3, 3, 1, 2, 4, 4, 2, 1, 2, 4, 2, 2, 0, 4, 4, 4, 2, 2, 3, 3, 1, 3, 0, 1, 1, 4, 0, 0, 0, 3, 1, 1, 0, 3, 4, 4, 3, 2, 0, 2, 0, 3, 2, 0, 0, 1, 1, 2]
POBP (disc): tot_buckets=5, mapping=[1, 4, 1, 2, 0, 2, 3, 3, 1, 0, 4, 4, 1, 2, 1, 0, 2, 1, 2, 1, 4, 0, 0, 2, 3, 3, 2, 4, 2, 1, 0, 2, 2, 4, 4, 3, 0, 2, 3, 3, 4, 4, 0, 2, 3, 4, 3, 1, 0, 4, 1, 4, 1, 0, 3, 4, 3, 1, 1, 3, 3, 2, 4, 0, 2, 0, 2, 0, 1, 0, 2, 0, 3, 4, 2, 1, 2, 4, 4, 2, 4, 2, 4, 1, 0, 1, 4, 2, 0, 2, 3, 2, 4, 1, 3, 3, 1, 1, 4, 4, 0, 2, 3, 0, 2, 3, 4, 4, 1, 4, 2, 2, 2, 1, 1, 0, 3, 2, 1, 1, 1, 1, 4, 4, 1, 3, 4, 4, 0, 4, 0, 1, 1, 3, 2, 2, 1, 3, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 2, 1, 0, 0, 4, 2, 3, 4, 4, 1, 3, 0, 0, 4, 2, 0, 1, 3, 3, 2, 4, 2, 2, 1, 1, 3, 0, 4, 4, 3, 3, 1, 1, 4, 4, 0, 1, 3, 2, 4, 1, 1, 2, 0, 2, 1, 3, 0, 3, 2, 2, 1, 4, 2, 1, 4, 4, 3, 4, 2, 2, 3, 1]
RELP (disc): tot_buckets=5, mapping=[2, 2, 1, 1, 3, 1, 3, 2, 1, 4, 3, 4, 4, 2, 4, 4, 0]
SEX (disc): tot_buckets=5, mapping=[0, 0]
RAC1P (disc): tot_buckets=5, mapping=[1, 0, 4, 1, 3, 0, 3, 1, 2]
Used 50 buckets in total
================
k_anon=1 , l_div=-0.0, size=12058
Final results:
----> Evaluating: Training new classifiers and a new adversary on 1-hot buckets (50 fts) - torch.Size([57714, 733]) points
----> Evaluating: Training classifier 1
[Trying CLF with wd=1e-06] 0.791 -> 0.776
[Trying CLF with wd=1e-05] 0.789 -> 0.777
[Trying CLF with wd=0.0001] 0.789 -> 0.778
[Trying CLF with wd=0.001] 0.785 -> 0.779
[Trying CLF with wd=0.002] 0.784 -> 0.777
[Trying CLF with wd=0.004] 0.783 -> 0.778
[Trying CLF with wd=0.006] 0.782 -> 0.777
[Trying CLF with wd=0.008] 0.782 -> 0.776
[Trying CLF with wd=0.01] 0.781 -> 0.774
[Trying CLF with wd=0.02] 0.779 -> 0.769
[Trying CLF with wd=0.05] 0.774 -> 0.764
Chose 0.001
[clf] train_acc=0.785, val_acc=0.779, test_acc=0.784
Adversary uses torch.Size([57714, 733]) points!
[Trying ADV with wd=1e-06] 0.635 -> 0.633
[Trying ADV with wd=1e-05] 0.629 -> 0.628
[Trying ADV with wd=0.0001] 0.632 -> 0.631
[Trying ADV with wd=0.001] 0.636 -> 0.635
[Trying ADV with wd=0.002] 0.632 -> 0.631
[Trying ADV with wd=0.004] 0.622 -> 0.622
[Trying ADV with wd=0.006] 0.615 -> 0.615
[Trying ADV with wd=0.008] 0.620 -> 0.620
[Trying ADV with wd=0.01] 0.623 -> 0.623
[Trying ADV with wd=0.02] 0.610 -> 0.611
[Trying ADV with wd=0.05] 0.602 -> 0.602
Chose 0.001
[adv test] adv accuracy per feature:
	feat=COW: tr= 0.840, va= 0.838, te= 0.838
	feat=MAR: tr= 0.786, va= 0.782, te= 0.782
	feat=OCCP: tr= 0.103, va= 0.102, te= 0.100
	feat=POBP: tr= 0.634, va= 0.634, te= 0.634
	feat=RELP: tr= 0.666, va= 0.670, te= 0.663
	feat=SEX: tr= 0.586, va= 0.580, te= 0.582
	feat=RAC1P: tr= 0.837, va= 0.840, te= 0.840
[adv] train_acc=0.636, val_acc=0.635, test_acc=0.634
[ADV Quantile] 0.99: 0.720
[ADV Quantile] 0.98: 0.727
[ADV Quantile] 0.95: 0.714
[ADV Quantile] 0.90: 0.708
[ADV Quantile] 0.80: 0.702
[ADV Quantile] 0.50: 0.688
[ADV Quantile] 0.00: 0.634
[ADV EXACT] train_acc=699.0/57714, val_acc=121.0/9619, test_acc=339.0/28857
Adversary uses torch.Size([57714, 733]) points!
[Trying ADV with wd=1e-06] 0.512 -> 0.513
[Trying ADV with wd=1e-05] 0.513 -> 0.512
[Trying ADV with wd=0.0001] 0.509 -> 0.510
[Trying ADV with wd=0.001] 0.509 -> 0.508
[Trying ADV with wd=0.002] 0.505 -> 0.505
[Trying ADV with wd=0.004] 0.500 -> 0.502
[Trying ADV with wd=0.006] 0.492 -> 0.494
[Trying ADV with wd=0.008] 0.494 -> 0.496
[Trying ADV with wd=0.01] 0.491 -> 0.494
[Trying ADV with wd=0.02] 0.474 -> 0.477
[Trying ADV with wd=0.05] 0.473 -> 0.475
Chose 1e-06
[adv test] adv accuracy per feature:
	feat=COW: tr= 0.653, va= 0.657, te= 0.652
	feat=MAR: tr= 0.683, va= 0.683, te= 0.682
	feat=OCCP: tr= 0.065, va= 0.066, te= 0.063
	feat=POBP: tr= 0.463, va= 0.461, te= 0.457
	feat=RELP: tr= 0.479, va= 0.482, te= 0.476
	feat=SEX: tr= 0.607, va= 0.597, te= 0.602
	feat=RAC1P: tr= 0.633, va= 0.643, te= 0.636
[adv] train_acc=0.512, val_acc=0.513, test_acc=0.510
[ADV Quantile] 0.99: 0.755
[ADV Quantile] 0.98: 0.747
[ADV Quantile] 0.95: 0.744
[ADV Quantile] 0.90: 0.732
[ADV Quantile] 0.80: 0.723
[ADV Quantile] 0.50: 0.682
[ADV Quantile] 0.00: 0.510
[ADV EXACT] train_acc=140.0/57714, val_acc=25.0/9619, test_acc=55.0/28857
==================
{'clf': [(0.7852167585173941, 0.779394947375809, 0.7838306129670678)], 'adv_recovery-ops': [(0.635927354721482, 0.6352440413451733, 0.6339915422663828)], 'adv_recovery': [(0.5117394565080685, 0.5127645922698697, 0.5097919584413244)]}
