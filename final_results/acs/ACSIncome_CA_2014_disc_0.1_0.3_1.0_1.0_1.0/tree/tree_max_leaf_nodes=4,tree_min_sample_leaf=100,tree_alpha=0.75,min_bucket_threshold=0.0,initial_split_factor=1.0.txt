-------------------------------------CONFIG-------------------------------------
neptune_config:
 neptune_run_label: None
 use_neptune: False
dataset_config:
 dataset: ACSIncome
 acs_state: CA
 acs_year: 2014
 shift_state: None
 shift_year: None
 freeze_feature: []
 add_syn: False
 bucketization_percent: 1.0
 train_percent: 1.0
 adv_percent: 1.0
 sens_feats: disc
 val_split: 0.1
 test_split: 0.3
 batch_size: 256
eval_config:
Classifiers:
 Classifier 0:
  Model: mlp2 Epochs: 20 LR: 0.01 WD: 0.0
Adversary 0:
  Model: mlp2 Epochs: 20 LR: 0.01 WD: 0.0
Adversary 1:
  Model: mlp2 Epochs: 20 LR: 0.01 WD: 0.0
min_config:
tree_max_leaf_nodes=4,tree_min_sample_leaf=100,tree_alpha=0.75,min_bucket_threshold=0.0,initial_split_factor=1.0
seed: 123
device: cpu
out_dir: final_results/acs
compute_guarantees: False
get_clf_upper_bound: False
fairness_sens_col: None
num_workers: 12
logger_level: INFO
-----------------------------------CONFIG END-----------------------------------

majority class acc (clf ACC LB): train_acc=0.643 test_acc=0.651
feat=COW, majority_freqs: train=0.653 test=0.652
feat=MAR, majority_freqs: train=0.534 test=0.536
feat=OCCP, majority_freqs: train=0.032 test=0.030
feat=POBP, majority_freqs: train=0.462 test=0.458
feat=RELP, majority_freqs: train=0.479 test=0.476
feat=SEX, majority_freqs: train=0.534 test=0.535
feat=RAC1P, majority_freqs: train=0.633 test=0.636
[adv] naive majority freq guess (adv ACC LB): train_acc=0.475, test_acc=0.474

Running data minimizer: tree
Final bucketizations:
================
Bucketization:
AGEP (cont): tot_buckets=2, borders=[0.149]
		Train set values would map to 2 buckets: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
SCHL (cont): tot_buckets=1, borders=[]
		Train set values would map to 1 buckets: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
WKHP (cont): tot_buckets=2, borders=[0.352]
		Train set values would map to 2 buckets: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
COW (disc): tot_buckets=1, mapping=[0, 0, 0, 0, 0, 0, 0, 0]
MAR (disc): tot_buckets=1, mapping=[0, 0, 0, 0, 0]
OCCP (disc): tot_buckets=2, mapping=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0]
POBP (disc): tot_buckets=1, mapping=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
RELP (disc): tot_buckets=1, mapping=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
SEX (disc): tot_buckets=1, mapping=[0, 0]
RAC1P (disc): tot_buckets=1, mapping=[0, 0, 0, 0, 0, 0, 0, 0, 0]
Used 13 buckets in total
================
k_anon=743 , l_div=0.03574115037918091, size=8
Final results:
----> Evaluating: Training new classifiers and a new adversary on 1-hot buckets (13 fts) - torch.Size([57714, 733]) points
----> Evaluating: Training classifier 1
[Trying CLF with wd=1e-06] 0.805 -> 0.799
[Trying CLF with wd=1e-05] 0.805 -> 0.799
[Trying CLF with wd=0.0001] 0.805 -> 0.799
[Trying CLF with wd=0.001] 0.805 -> 0.799
[Trying CLF with wd=0.002] 0.805 -> 0.799
[Trying CLF with wd=0.004] 0.805 -> 0.799
[Trying CLF with wd=0.006] 0.805 -> 0.799
[Trying CLF with wd=0.008] 0.805 -> 0.799
[Trying CLF with wd=0.01] 0.805 -> 0.799
[Trying CLF with wd=0.02] 0.805 -> 0.799
[Trying CLF with wd=0.05] 0.805 -> 0.799
Chose 0.05
[clf] train_acc=0.805, val_acc=0.799, test_acc=0.800
Adversary uses torch.Size([57714, 733]) points!
[Trying ADV with wd=1e-06] 0.503 -> 0.504
[Trying ADV with wd=1e-05] 0.502 -> 0.503
[Trying ADV with wd=0.0001] 0.501 -> 0.503
[Trying ADV with wd=0.001] 0.508 -> 0.510
[Trying ADV with wd=0.002] 0.505 -> 0.504
[Trying ADV with wd=0.004] 0.502 -> 0.502
[Trying ADV with wd=0.006] 0.479 -> 0.481
[Trying ADV with wd=0.008] 0.494 -> 0.496
[Trying ADV with wd=0.01] 0.492 -> 0.494
[Trying ADV with wd=0.02] 0.477 -> 0.479
[Trying ADV with wd=0.05] 0.474 -> 0.477
Chose 0.001
[adv test] adv accuracy per feature:
	feat=COW: tr= 0.653, va= 0.657, te= 0.652
	feat=MAR: tr= 0.680, va= 0.675, te= 0.681
	feat=OCCP: tr= 0.063, va= 0.063, te= 0.060
	feat=POBP: tr= 0.463, va= 0.461, te= 0.457
	feat=RELP: tr= 0.479, va= 0.482, te= 0.476
	feat=SEX: tr= 0.588, va= 0.588, te= 0.588
	feat=RAC1P: tr= 0.633, va= 0.643, te= 0.636
[adv] train_acc=0.508, val_acc=0.510, test_acc=0.507
[ADV Quantile] 0.99: 0.560
[ADV Quantile] 0.98: 0.560
[ADV Quantile] 0.95: 0.544
[ADV Quantile] 0.90: 0.537
[ADV Quantile] 0.80: 0.537
[ADV Quantile] 0.50: 0.523
[ADV Quantile] 0.00: 0.507
[ADV EXACT] train_acc=194.0/57714, val_acc=33.0/9619, test_acc=90.0/28857
Adversary uses torch.Size([57714, 733]) points!
[Trying ADV with wd=1e-06] 0.501 -> 0.503
[Trying ADV with wd=1e-05] 0.487 -> 0.488
[Trying ADV with wd=0.0001] 0.504 -> 0.504
[Trying ADV with wd=0.001] 0.503 -> 0.504
[Trying ADV with wd=0.002] 0.505 -> 0.506
[Trying ADV with wd=0.004] 0.495 -> 0.496
[Trying ADV with wd=0.006] 0.493 -> 0.496
[Trying ADV with wd=0.008] 0.475 -> 0.477
[Trying ADV with wd=0.01] 0.493 -> 0.495
[Trying ADV with wd=0.02] 0.476 -> 0.478
[Trying ADV with wd=0.05] 0.472 -> 0.474
Chose 0.002
[adv test] adv accuracy per feature:
	feat=COW: tr= 0.653, va= 0.657, te= 0.652
	feat=MAR: tr= 0.680, va= 0.675, te= 0.681
	feat=OCCP: tr= 0.041, va= 0.037, te= 0.038
	feat=POBP: tr= 0.463, va= 0.461, te= 0.457
	feat=RELP: tr= 0.479, va= 0.482, te= 0.476
	feat=SEX: tr= 0.589, va= 0.588, te= 0.587
	feat=RAC1P: tr= 0.633, va= 0.643, te= 0.636
[adv] train_acc=0.505, val_acc=0.506, test_acc=0.504
[ADV Quantile] 0.99: 0.580
[ADV Quantile] 0.98: 0.580
[ADV Quantile] 0.95: 0.584
[ADV Quantile] 0.90: 0.582
[ADV Quantile] 0.80: 0.552
[ADV Quantile] 0.50: 0.536
[ADV Quantile] 0.00: 0.504
[ADV EXACT] train_acc=115.0/57714, val_acc=21.0/9619, test_acc=42.0/28857
==================
{'clf': [(0.804744082889434, 0.7992514818705396, 0.80011782245634)], 'adv_recovery-ops': [(0.5083376565540748, 0.5098295601687037, 0.5070576501536912)], 'adv_recovery': [(0.5053030720331462, 0.5061620687015523, 0.5038784882560015)]}
