-------------------------------------CONFIG-------------------------------------
neptune_config:
 neptune_run_label: None
 use_neptune: False
dataset_config:
 dataset: loan
 acs_state: CT
 acs_year: 2014
 shift_state: None
 shift_year: None
 freeze_feature: []
 add_syn: False
 bucketization_percent: 1.0
 train_percent: 1.0
 adv_percent: 1.0
 sens_feats: disc
 val_split: 0.1
 test_split: 0.3
 batch_size: 256
eval_config:
Classifiers:
 Classifier 0:
  Model: mlp2 Epochs: 20 LR: 0.01 WD: 0.0
Adversary 0:
  Model: mlp2 Epochs: 20 LR: 0.01 WD: 0.0
min_config:
featsel_k=all,method=anova
seed: 123
device: cpu
out_dir: final_results2/loan
compute_guarantees: False
get_clf_upper_bound: False
fairness_sens_col: None
num_workers: 12
logger_level: INFO
-----------------------------------CONFIG END-----------------------------------

majority class acc (clf ACC LB): train_acc=0.688 test_acc=0.670
feat=Gender, majority_freqs: train=0.818 test=0.795
feat=Married, majority_freqs: train=0.655 test=0.643
feat=Dependents, majority_freqs: train=0.587 test=0.562
feat=Education, majority_freqs: train=0.799 test=0.719
feat=Self_Employed, majority_freqs: train=0.848 test=0.827
feat=Property_Area, majority_freqs: train=0.378 test=0.384
[adv] naive majority freq guess (adv ACC LB): train_acc=0.681, test_acc=0.655

Running data minimizer: featsel
Support: [ True  True  True  True  True  True  True  True  True  True  True]
ApplicantIncome kept
CoapplicantIncome kept
Loan_Amount kept
Loan_Amount_Term kept
Credit_History kept
Gender kept
Married kept
Dependents kept
Education kept
Self_Employed kept
Property_Area kept
================
Bucketization:
ApplicantIncome (cont): tot_buckets=100, borders=[0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.1, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.2, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.3, 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.4, 0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.5, 0.51, 0.52, 0.53, 0.54, 0.55, 0.56, 0.57, 0.58, 0.59, 0.6, 0.61, 0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.69, 0.7, 0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77, 0.78, 0.79, 0.8, 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87, 0.88, 0.89, 0.9, 0.91, 0.92, 0.93, 0.94, 0.95, 0.96, 0.97, 0.98, 0.99]
		Train set values would map to 33 buckets: [0, 0, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 10, 10, 10, 10, 10, 10, 11, 11, 11, 11, 11, 11, 12, 12, 12, 12, 12, 13, 13, 13, 14, 14, 14, 14, 14, 14, 14, 15, 15, 15, 16, 16, 16, 17, 17, 17, 17, 18, 18, 19, 20, 21, 22, 22, 23, 23, 23, 25, 31, 31, 32, 37, 53, 61, 63, 81, 99]
CoapplicantIncome (cont): tot_buckets=100, borders=[0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.1, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.2, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.3, 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.4, 0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.5, 0.51, 0.52, 0.53, 0.54, 0.55, 0.56, 0.57, 0.58, 0.59, 0.6, 0.61, 0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.69, 0.7, 0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77, 0.78, 0.79, 0.8, 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87, 0.88, 0.89, 0.9, 0.91, 0.92, 0.93, 0.94, 0.95, 0.96, 0.97, 0.98, 0.99]
		Train set values would map to 52 buckets: [0, 1, 4, 6, 6, 6, 6, 7, 7, 8, 8, 8, 8, 9, 9, 9, 9, 9, 9, 10, 10, 10, 11, 11, 11, 11, 11, 12, 12, 12, 12, 12, 12, 12, 13, 13, 13, 13, 14, 14, 14, 14, 14, 14, 14, 14, 14, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 17, 17, 17, 17, 17, 18, 18, 18, 18, 18, 18, 18, 18, 18, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 20, 20, 20, 20, 20, 20, 20, 20, 21, 21, 21, 21, 21, 21, 22, 22, 22, 22, 22, 22, 22, 23, 24, 24, 25, 25, 25, 25, 25, 26, 26, 26, 26, 26, 27, 27, 28, 28, 28, 28, 28, 29, 29, 29, 30, 30, 30, 30, 31, 31, 31, 32, 33, 33, 33, 34, 34, 35, 36, 36, 37, 37, 38, 39, 39, 39, 40, 40, 40, 42, 44, 44, 44, 46, 49, 50, 50, 55, 62, 63, 64, 68, 71, 79, 97, 99]
Loan_Amount (cont): tot_buckets=100, borders=[0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.1, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.2, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.3, 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.4, 0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.5, 0.51, 0.52, 0.53, 0.54, 0.55, 0.56, 0.57, 0.58, 0.59, 0.6, 0.61, 0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.69, 0.7, 0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77, 0.78, 0.79, 0.8, 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87, 0.88, 0.89, 0.9, 0.91, 0.92, 0.93, 0.94, 0.95, 0.96, 0.97, 0.98, 0.99]
		Train set values would map to 55 buckets: [0, 0, 1, 2, 3, 4, 4, 4, 5, 5, 5, 6, 6, 6, 6, 6, 6, 7, 7, 7, 8, 8, 8, 8, 9, 9, 9, 9, 9, 9, 10, 10, 10, 10, 10, 10, 11, 11, 11, 11, 11, 12, 12, 12, 12, 12, 12, 12, 13, 13, 13, 13, 13, 14, 14, 14, 14, 14, 14, 14, 15, 15, 15, 15, 15, 15, 16, 16, 16, 16, 16, 16, 17, 17, 17, 17, 17, 17, 17, 18, 18, 18, 18, 18, 18, 19, 19, 20, 20, 20, 20, 20, 21, 21, 21, 22, 22, 22, 22, 22, 22, 23, 23, 23, 23, 24, 24, 25, 25, 25, 25, 26, 26, 26, 27, 27, 28, 28, 29, 29, 30, 30, 31, 32, 33, 33, 33, 35, 35, 35, 36, 36, 37, 38, 38, 38, 39, 40, 41, 42, 43, 43, 44, 44, 46, 48, 52, 52, 61, 63, 68, 69, 70, 85, 92, 99]
Loan_Amount_Term (cont): tot_buckets=100, borders=[0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.1, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.2, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.3, 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.4, 0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.5, 0.51, 0.52, 0.53, 0.54, 0.55, 0.56, 0.57, 0.58, 0.59, 0.6, 0.61, 0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.69, 0.7, 0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77, 0.78, 0.79, 0.8, 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87, 0.88, 0.89, 0.9, 0.91, 0.92, 0.93, 0.94, 0.95, 0.96, 0.97, 0.98, 0.99]
		Train set values would map to 9 buckets: [0, 5, 10, 18, 32, 45, 59, 72, 99]
Credit_History (cont): tot_buckets=100, borders=[0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.1, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.2, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.3, 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.4, 0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.5, 0.51, 0.52, 0.53, 0.54, 0.55, 0.56, 0.57, 0.58, 0.59, 0.6, 0.61, 0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.69, 0.7, 0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77, 0.78, 0.79, 0.8, 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87, 0.88, 0.89, 0.9, 0.91, 0.92, 0.93, 0.94, 0.95, 0.96, 0.97, 0.98, 0.99]
		Train set values would map to 2 buckets: [0, 99]
Gender (disc): tot_buckets=2, mapping=[0, 1]
Married (disc): tot_buckets=2, mapping=[0, 1]
Dependents (disc): tot_buckets=6, mapping=[0, 1, 2, 3, 4, 5]
Education (disc): tot_buckets=2, mapping=[0, 1]
Self_Employed (disc): tot_buckets=2, mapping=[0, 1]
Property_Area (disc): tot_buckets=3, mapping=[0, 1, 2]
Used 517 buckets in total
================
k_anon=1 , l_div=-0.0, size=366
Final results:
----> Evaluating: Training new classifiers and a new adversary on 1-hot buckets (517 fts) - torch.Size([368, 22]) points
----> Evaluating: Training classifier 1
[Trying CLF with wd=1e-06] 0.851 -> 0.738
[Trying CLF with wd=1e-05] 0.864 -> 0.770
[Trying CLF with wd=0.0001] 0.856 -> 0.770
[Trying CLF with wd=0.001] 0.861 -> 0.770
[Trying CLF with wd=0.002] 0.840 -> 0.770
[Trying CLF with wd=0.004] 0.859 -> 0.787
[Trying CLF with wd=0.006] 0.799 -> 0.836
[Trying CLF with wd=0.008] 0.826 -> 0.820
[Trying CLF with wd=0.01] 0.799 -> 0.820
[Trying CLF with wd=0.02] 0.766 -> 0.836
[Trying CLF with wd=0.05] 0.753 -> 0.836
Chose 0.05
[clf] train_acc=0.753, val_acc=0.836, test_acc=0.789
Adversary uses torch.Size([368, 22]) points!
[Trying ADV with wd=1e-06] 1.000 -> 1.000
[Trying ADV with wd=1e-05] 1.000 -> 1.000
[Trying ADV with wd=0.0001] 1.000 -> 1.000
[Trying ADV with wd=0.001] 1.000 -> 1.000
[Trying ADV with wd=0.002] 1.000 -> 1.000
[Trying ADV with wd=0.004] 1.000 -> 1.000
[Trying ADV with wd=0.006] 1.000 -> 1.000
[Trying ADV with wd=0.008] 1.000 -> 1.000
[Trying ADV with wd=0.01] 1.000 -> 1.000
[Trying ADV with wd=0.02] 1.000 -> 1.000
[Trying ADV with wd=0.05] 1.000 -> 1.000
Chose 0.05
[adv test] adv accuracy per feature:
	feat=Gender: tr= 1.000, va= 1.000, te= 1.000
	feat=Married: tr= 1.000, va= 1.000, te= 1.000
	feat=Dependents: tr= 1.000, va= 1.000, te= 1.000
	feat=Education: tr= 1.000, va= 1.000, te= 1.000
	feat=Self_Employed: tr= 1.000, va= 1.000, te= 1.000
	feat=Property_Area: tr= 1.000, va= 1.000, te= 1.000
[adv] train_acc=1.000, val_acc=1.000, test_acc=1.000
[ADV Quantile] 0.99: 1.000
[ADV Quantile] 0.98: 1.000
[ADV Quantile] 0.95: 1.000
[ADV Quantile] 0.90: 1.000
[ADV Quantile] 0.80: 1.000
[ADV Quantile] 0.50: 1.000
[ADV Quantile] 0.00: 1.000
[ADV EXACT] train_acc=368.0/368, val_acc=61.0/61, test_acc=185.0/185
==================
{'clf': [(0.752717383529829, 0.8360655903816223, 0.7891891598701477)], 'adv_recovery-ops': [(1.0, 1.0, 1.0)]}
